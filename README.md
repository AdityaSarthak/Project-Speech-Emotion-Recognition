Speech Emotion Recognition with LSTM and MFCC


Overview


This project implements a Speech Emotion Recognition (SER) system using a Long Short-Term Memory (LSTM) neural network and Mel-Frequency Cepstral Coefficients (MFCC) extraction. The goal is to recognize the emotional content of speech audio files.

Features


Utilizes an LSTM model for speech emotion recognition.

Extracts MFCC features from speech audio files.

Trains the model on a labeled dataset of emotional speech samples.

Provides an interface for predicting the emotion of new speech audio files.




Requirements

Python 3.x

TensorFlow

Keras

Librosa

Numpy

Pandas

Flask


